EP1: Pthreads e OpenMP

Neste EP, foi implementado em C um algoritmo que multiplica duas matrizes A (dimensão m x n) e B (dimensão n x p) de três maneiras: sequencial, com a biblioteca de Pthreads e com diretivas de OpenMP. O algoritmo escolhido para fazer a operação foi o de multiplicação em blocos, que consiste em particionar as matrizes de entrada em matrizes menores para melhorar o aproveitamento do cache, reduzindo a quantidade de cache-misses. A quantidade de partições mais eficiente é dependente da arquitetura do computador: idealmente, deve-se particionar as matrizes nos maiores blocos que caibam totalmente no cache. Pesquisando a especificação de alguns processadores, observou-se que o tamanho do cache compartilhado (em geral, L3) pode variar bastante (entre 3 e 12 MB). O programa foi desenvolvido e testado num Intel i5 com quatro núcleos lógicos e 8MB de cache. Considerando o tamanho de cache de 8MB e sabendo que cada tipo double ocupa 8 bytes, o cache conseguiria armazenar duas matrizes quadradas de dimensão 706. Esse seria o tamanho de bloco máximo para essa arquitetura. Optou-se por definir blocos de tamanho 512. Para aproveitar ainda mais o cache, sabendo que a linguagem C armazena matrizes com ordenação 'row-major' (sequencialmente na horizontal), foi utilizada a matriz transposta de B para fazer os acessos aos elementos de B nas operações de soma.

Na versão sequencial, a implementação foi feita escrevendo seis laços aninhados, três externos que iteram ao longo dos tamanhos de bloco (m_block, n_block, p_block), e três internos que iteram dentro de cada bloco (m, n, p) fazendo as somas. A otimização do código sequencial já resultou num tempo de execução 60% menor do que uma versão 'crua', evidenciando a importância de se estruturar os dados de forma a minimizar movimentações na memória e no cache. Entretanto, ao adicionar a flag -O3 para compilar, os tempos de execução das versões sequenciais com e sem blocos ficou equivalente, o que indica que a compilação com nível de otimização 'máximo' já deve fazer alterações para aproveitamento de cache.

A partir da versão sequencial otimizada, foram desenvolvidas as versões em paralelo com pthreads e com OpenMP. Na multiplicação em blocos, os laços internos dependem do index dos laços externos; por isso, não foi possível paralelizar todos eles (por exemplo, usando a diretiva #pragma omp for collapse(6)). Paralelizar a multiplicação de cada bloco da matriz de saída também não pareceu vantajoso, pois deixaríamos de aproveitar o cache. Então, a solução foi paralelizar o cálculo dos elementos (produtos internos) dentro de um mesmo bloco. Com matrizes grandes, ambas as versões com pthreads e OpenMP rodam em cerca de 40% do tempo da versão sequencial.

Posteriormente, o código foi aprimorado para tirar proveito das instruções vetoriais da Intel. No laço mais interno da multiplicação, o produto dos elementos dois a dois foi substituído por uma função que retorna o produto interno de dois vetores de tamanho 8. Assim, o passo do laço interno foi aumentado de um para 8. As matrizes de entrada foram preenchidas com zeros até a próxima dimensão que fosse múltipla de 8, para evitar a inclusão de condicionais dentro dos laços, o que prejudicaria o desempenho. Essas modificações resultaram numa melhoria adicional de uns 10%. A alternativa de fazer o produto interno sem instruções vetoriais foi mantida para que o programa também funcione em processadores que não suportam AVX.

Ao longo do desenvolvimento do programa, ficou clara a importância de se conhecer a arquitetura do computador para otimizar códigos tanto sequenciais quanto paralelizados, e de se observar as dependências entre as variáveis. Algumas das possíveis melhorias no código seriam: ler parâmetros tais como quantidade de cores e tamanho do cache do computador (por exemplo, através de comandos no Makefile) e enviá-los como variáveis de entrada, otimizar o cálculo da matriz B transposta (ele não foi feito usando blocos nem processos em paralelo).